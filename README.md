# Sistemas Distribuidos 

RepositÃ³rio para armazenar os trabalhos feitos durante a disciplina de Sistemas Distribuidos da Universidade Federal Fluminense

# Trabalho 1 

## Sistema de PubSub com gRPC em Java

Um sistema simples de publicaÃ§Ã£o/assinatura (PubSub) implementado com gRPC em Java, usando Maven como gerenciador de dependÃªncias.

## ğŸ“‹ PrÃ©-requisitos

- Java JDK 17+
- Maven 3.6+
- IDE de sua preferÃªncia (opcional)

```bash
sudo apt install openjdk-21-jdk
sudo apt install maven
```

## ğŸ› ï¸ ConfiguraÃ§Ã£o do Projeto

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/ArthurPxto/sistemas_distribuidos
cd grpc-pubsub
```

2. Compile o projeto:
```bash
mvn clean compile
```

## ğŸš€ Como Executar

### 1. Iniciar o Servidor

Abra um terminal e execute:
```bash
mvn clean package -Prun-server
```

### 2. Iniciar Assinantes (Subscribers)

Em terminais separados, execute:
```bash
mvn exec:java -Dexec.mainClass="com.example.pubsub.Subscriber"
```

VocÃª pode iniciar mÃºltiplos assinantes simultaneamente.

### 3. Publicar Mensagens (Publisher)

Em outro terminal, execute:
```bash
mvn exec:java -Dexec.mainClass="com.example.pubsub.Publisher"
```

## ğŸ”§ Estrutura do Projeto

```
grpc-pubsub/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/com/example/pubsub/
â”‚   â”‚   â”‚   â”œâ”€â”€ PubSubServer.java      # Servidor gRPC
â”‚   â”‚   â”‚   â”œâ”€â”€ PubSubServiceImpl.java # ImplementaÃ§Ã£o do serviÃ§o
â”‚   â”‚   â”‚   â”œâ”€â”€ Publisher.java         # Cliente publicador
â”‚   â”‚   â”‚   â””â”€â”€ Subscriber.java        # Cliente assinante
â”‚   â”‚   â””â”€â”€ proto/
â”‚   â”‚       â””â”€â”€ pubsub.proto           # DefiniÃ§Ã£o do serviÃ§o gRPC
â”œâ”€â”€ pom.xml                            # ConfiguraÃ§Ã£o do Maven
â””â”€â”€ README.md
```

## ğŸ’¡ Funcionamento

1. O **Servidor** mantÃ©m uma lista de assinantes ativos
2. **Publicadores** enviam mensagens ao servidor
3. O servidor distribui as mensagens para todos os **Assinantes** conectados
- Assim que um novo assinante se interessa pelo assunto, ele recebe todas as mensagens anteriores
4. Assinantes recebem as mensagens em tempo real

## ğŸ›‘ Encerrando a AplicaÃ§Ã£o

Pressione `Ctrl+C` em cada terminal para encerrar os processos.

## ğŸ“š DependÃªncias Principais

- gRPC (1.64.0)
- Protocol Buffers (3.25.3)
- Maven Compiler Plugin (3.11.0)

## ğŸ”„ Fluxo de Mensagens

```mermaid
sequenceDiagram
    Publisher->>Servidor: Publica mensagem
    Servidor->>Subscriber1: Encaminha mensagem
    Servidor->>Subscriber2: Encaminha mensagem
    Servidor->>SubscriberN: Encaminha mensagem
```

## ğŸ› SoluÃ§Ã£o de Problemas

Se encontrar erros de compilaÃ§Ã£o:
```bash
mvn clean compile
```

Para ver logs detalhados:
```bash
mvn exec:java -Dexec.mainClass="com.example.pubsub.PubSubServer" -X
```
# Trabalho 2

# Projeto de Monitoramento de Sinais Vitais com Spark, Kafka e IA

Este projeto simula a leitura de sinais vitais de pacientes, realiza prÃ©-processamento com Spark Structured Streaming, envia os dados para o Kafka, e utiliza um modelo de aprendizado de mÃ¡quina para classificar os dados em trÃªs categorias: `normal`, `alerta` ou `emergÃªncia`.

## âš™ï¸ Tecnologias utilizadas

- Apache Kafka
- Apache Spark 4.0.0
- PySpark
- scikit-learn
- Confluent Kafka Python client (`confluent_kafka`)
- Docker (para Kafka/Zookeeper)
- Pandas
- joblib

## ğŸ“ Estrutura do Projeto

ML/
.
â”œâ”€â”€ atifacts/
â”œâ”€â”€ libs/
    â””â”€â”€ jsr305-3.0.0.jar
â”œâ”€â”€ output/
    â””â”€â”€ sinais_vitais.csv
â”œâ”€â”€ gerador.py
â”œâ”€â”€ pre_precessor.py
â”œâ”€â”€ training.py
â”œâ”€â”€ consumer_ia.py
â”œâ”€â”€ consumer.py
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ modelo_risco.pkl
â””â”€â”€ README.md

## ğŸ”§ Requisitos

- Python 3.12
- Java 8+
- Apache Maven
- Apache Spark 4.0.0 instalado manualmente
- Kafka rodando localmente (pode usar Docker)

---

## ğŸ“¦ InstalaÃ§Ã£o das dependÃªncias Python

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## âš ï¸ DependÃªncia ausente: `jsr305-3.0.0.jar`

O pacote `jsr305:3.0.0` **nÃ£o Ã© encontrado automaticamente pelo Spark**. VocÃª precisa fazer o seguinte:

### Baixe o arquivo `jsr305-3.0.0.jar` manualmente e instale com o Maven:

```bash
mvn install:install-file \
  -Dfile=jsr305-3.0.0.jar \
  -DgroupId=com.google.code.findbugs \
  -DartifactId=jsr305 \
  -Dversion=3.0.0 \
  -Dpackaging=jar
```

---

## ğŸš€ Executando o prÃ©-processador com Spark

Use o comando abaixo para rodar o script com a dependÃªncia Kafka:

```bash
spark-submit \
  --repositories https://repo1.maven.org/maven2 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0 \
  pre_precessor.py
```

---

## ğŸ’¡ Fluxo do Projeto

1. **Sensores geram sinais vitais** â†’ enviados para o Kafka (`sinais-vitais`)
2. **`pre_precessor.py`** consome os sinais vitais, classifica o risco com regras simples, e publica no tÃ³pico `sinais-processados`
3. **`consumidor_ia.py`** recebe os dados e alimenta o modelo de IA treinado

---

## âœ… ExecuÃ§Ã£o da IA

ApÃ³s o `pre_precessor.py` estar em execuÃ§Ã£o e publicando no Kafka, vocÃª pode iniciar a IA com:

```bash
python consumidor_ia.py
```

---

## ğŸ“Š Treinamento de modelo

```bash
python treinamento.py
```

Gera um modelo salvo em disco com `joblib` que serÃ¡ usado pela IA.

---

## ğŸ§  MÃ©tricas de desempenho

O modelo de regressÃ£o logÃ­stica obteve os seguintes resultados:

```
              precision    recall  f1-score   support
      alerta       0.73      0.81      0.77        69
  emergÃªncia       0.79      0.66      0.72        47
      normal       0.81      0.81      0.81        47
    accuracy                           0.77       163
   macro avg       0.78      0.76      0.77       163
weighted avg       0.77      0.77      0.77       163
```

---

## ğŸ³ Kafka com Docker (opcional)

```bash
# Subir Kafka com Docker
docker-compose up -d

# Entrar no container do Kafka
docker exec -it kafka bash

# Criar o tÃ³pico de sinais-vitais criados pelo gerador
kafka-topics --create --topic sinais-vitais --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# Criar o topico sinais-processados criados pelo pre-precessor
kafka-topics --create --topic sinais-processados --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1


# Listar os tÃ³picos
kafka-topics --list --bootstrap-server localhost:9092
```

---

## ğŸ“ ObservaÃ§Ãµes

- Os arquivos `.jar` devem estar disponÃ­veis localmente se nÃ£o forem encontrados via pacotes do spark.
- O modelo de IA pode ser trocado por outro (Ã¡rvore, random forest, etc.).
- O projeto funciona em tempo real com Spark Structured Streaming.